{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1e6cc80",
   "metadata": {},
   "source": [
    "# **Week 5: Feature Selection and Regularization on the Ames Housing Dataset**\n",
    "\n",
    "In this homework, we will experiment with two feature selection methods and one regularization technique for linear regression:\n",
    "- **Forward Selection**\n",
    "- **Backward Selection**\n",
    "- **Ridge Regression**\n",
    "\n",
    "We will apply these techniques to the preprocessed Ames Housing dataset from last week, evaluate which method achieves the best cross-validation (CV) score, and provide a final test score for the best model. \n",
    "\n",
    "There are 4 problems with 8 graded answers worth 6 points each, and you get 2 points free. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f38fcab-bcb2-4b70-a304-6412d94a36df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful imports\n",
    "\n",
    "import os\n",
    "import kagglehub\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import io\n",
    "import zipfile\n",
    "\n",
    "from sklearn.model_selection   import train_test_split, cross_val_score\n",
    "from sklearn.linear_model      import LinearRegression,Ridge,Lasso\n",
    "from sklearn.model_selection   import GridSearchCV\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.metrics           import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing     import StandardScaler \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241380b6-01ad-4a90-91ee-d5c4f53b9218",
   "metadata": {},
   "source": [
    "## **Prelude: Download the Preprocessed Ames Housing Dataset**\n",
    "\n",
    "I have stored the dataset as a zipped directory containing the following four files from an 80%-20% split of the Ames dataset after preprocessing (as done in the last homework):\n",
    "\n",
    "- `X_train.csv`         \n",
    "- `y_train.csv`\n",
    "- `X_test.csv`          \n",
    "- `y_test.csv`\n",
    "\n",
    "**TODO:** Run the following cell to download and extract the dataset into the current working directory of this notebook.  \n",
    "Alternatively, you can manually download the zip file from the provided URL, extract it, and place the files in the same directory as your notebook.\n",
    "\n",
    "> ⚠️ **Important:**  \n",
    "> DO NOT use your own version of these datasets from the last homework. The autograder expects the exact split provided in my files for both training and testing sets. Using any other split will result in incorrect results during grading.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd27c153-4225-4556-9515-cb6a917f4221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files downloaded and extracted successfully.\n",
      "Training and testing datasets loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Download the Ames Housing Dataset from Snyder's web site\n",
    "\n",
    "# URL to the zip file\n",
    "zip_url = \"https://www.cs.bu.edu/fac/snyder/cs505/Data/ames_housing.zip\"\n",
    "\n",
    "try:\n",
    "    response = requests.get(zip_url)\n",
    "    response.raise_for_status()  # Raise an error for bad status codes\n",
    "    with zipfile.ZipFile(io.BytesIO(response.content)) as zipf:\n",
    "        zipf.extractall(\"ames_data\")\n",
    "    print(\"Files downloaded and extracted successfully.\")\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"Error downloading the file: {e}\")\n",
    "\n",
    "# Load the datasets\n",
    "X_train = pd.read_csv(\"ames_data/X_train.csv\")\n",
    "X_test = pd.read_csv(\"ames_data/X_test.csv\")\n",
    "y_train = pd.read_csv(\"ames_data/y_train.csv\").squeeze(\"columns\")          # converted to a Series\n",
    "y_test = pd.read_csv(\"ames_data/y_test.csv\").squeeze(\"columns\")\n",
    "\n",
    "print(\"Training and testing datasets loaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac6da55-0dc7-4509-b2d7-afd475af4060",
   "metadata": {},
   "source": [
    "## **Problem One: Forward Selection with the Ames Dataset**\n",
    "\n",
    "For our first experiment we will apply the forward feature selection algorithm to the dataset. Follow these steps, using the notebook from this week's video lesson as a resource as necessary. \n",
    "\n",
    "**If you have not looked at the video yet, please do it now before continuing.**\n",
    "\n",
    "**Steps to Follow:**\n",
    "1. **Observe** that we have provided the `forward_feature_selection` algorithm from the video notebook for you to use.\n",
    "\n",
    "2. **Copy** from the video notebook into the cell indicated below the code that runs forward feature selection and generates a plot (excluding the part that prints the test MSE--we'll do that at the end of this homework). Or write your own version!\n",
    "\n",
    "3. **Modify** this code to display the **Root Mean Squared Error (RMSE)** instead of MSE.  \n",
    "   - *Remember*: RMSE is the square root of MSE, which provides results in dollars rather than dollars squared, making the metric more interpretable.  \n",
    "   - Both the plot of RMSE vs. the number of selected features and the printout of the Best CV Score should use RMSE.\n",
    "\n",
    "4. **Run** the code on `X_train` and `y_train` (keeping all default settings) to:\n",
    "   - Generate the plot of **Root Mean Squared Error (RMSE)** vs. **Features Added**, and  \n",
    "   - Print the **Best Feature Set** found and the **Best CV RMSE Score**.\n",
    "\n",
    "**Hints:**\n",
    "- The feature names will be more legible if you increase the size of the plot and change the angle and size of the xticks, e.g.,\n",
    "\n",
    "        plt.xticks(range(1, len(selected_features_forward) + 1), selected_features_forward, rotation=60, ha='right', fontsize=6) \n",
    "\n",
    "- You may wish to change the bounds of the y-axis using `plt.ylim(...)` to better see the behavior around the minimum point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7227d05b-cc9a-4193-9a5e-703172193095",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Forward Feature Selection\n",
    "\n",
    "def forward_feature_selection(X, y, model, \n",
    "                              scoring='neg_mean_squared_error', \n",
    "                              cv=5, \n",
    "                              tol=None,               # None = no delta cutoff\n",
    "                                                      # use 0.0 for \"no further improvements\"\n",
    "                                                      # and 1e-4 for \"point of diminishing returns\"                                      \n",
    "                              max_features=None,      # None = use all features\n",
    "                              n_jobs=-1,\n",
    "                              verbose=False\n",
    "                             ):\n",
    "    selected_features = []                            # List to store the order of features selected\n",
    "    remaining_features = list(X.columns)              # Features not yet selected\n",
    "    best_scores = []                                  # List to store the CV score after each feature addition\n",
    "    previous_score = float('inf')                     # Initialize previous score for improvement comparison\n",
    "\n",
    "    # Track the best subset of features and its corresponding score\n",
    "    \n",
    "    best_feature_set = None                           # Best combination of features found so far\n",
    "    best_score = float('inf')                         # Best CV score observed so far\n",
    "    \n",
    "    while remaining_features:\n",
    "        scores = {}                                   # Dictionary to hold CV scores for each candidate feature\n",
    "        for feature in remaining_features:\n",
    "            current_features = selected_features + [feature]\n",
    "            \n",
    "            # Compute the CV score for the current set of features (negated MSE, so lower is better)\n",
    "            cv_score = -cross_val_score(model, X[current_features], y, \n",
    "                                        scoring=scoring, cv=cv, n_jobs=n_jobs\n",
    "                                       ).mean()\n",
    "            scores[feature] = cv_score\n",
    "\n",
    "        # Select the feature that minimizes the CV score\n",
    "        best_feature = min(scores, key=scores.get)\n",
    "        current_score = scores[best_feature]\n",
    "            \n",
    "        # Check if the improvement is significant based on the tolerance (tol)\n",
    "        if tol is not None and previous_score - current_score < tol:\n",
    "            if verbose:\n",
    "                print(\"Stopping early due to minimal improvement.\")\n",
    "            break\n",
    "\n",
    "        # Add the best feature to the selected list and update score trackers\n",
    "        selected_features.append(best_feature)\n",
    "        best_scores.append(current_score)\n",
    "        remaining_features.remove(best_feature)\n",
    "        previous_score = current_score\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"\\nFeatures: {selected_features[-3:]}, CV Score (MSE): {current_score:.4f}\")\n",
    "        \n",
    "        # Update the best subset if the current score is better than the best so far\n",
    "        if current_score < best_score:\n",
    "            best_score = current_score\n",
    "            best_feature_set = selected_features.copy()\n",
    "        \n",
    "        # Check if the maximum number of features has been reached\n",
    "        if max_features is not None and len(selected_features) >= max_features:\n",
    "            break\n",
    "\n",
    "    return (\n",
    "        selected_features,      # List of features in the order they were selected (this will be ALL features if max_features == None\n",
    "        best_scores,            # List of cross-validation scores corresponding to each addition in the previous list\n",
    "        best_feature_set,       # The subset of features that achieved the best CV score.\n",
    "        best_score              # The best CV score\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8dca9413-91ff-46c1-9a95-a284bdc4f005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:  Run Forward Feature Selection, plot the results, and print out the Best Feature Set and the Best CV Score found. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ae3910-401e-4529-a33c-775d79fe16b4",
   "metadata": {},
   "source": [
    "### Problem One Graded Answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4fecff6-613e-4950-b65c-ddbd4d4006d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a1a = Ellipsis\n"
     ]
    }
   ],
   "source": [
    "# TODO:  Set the variable to the number of features in the best feature set found\n",
    "\n",
    "a1a = ...\n",
    "\n",
    "print(f'a1a = {a1a}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e163c98-412b-4a45-8abe-1347942c5fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a1b = $0.00\n"
     ]
    }
   ],
   "source": [
    "# TODO:  Set the variable to the best CV RMSE score found\n",
    "\n",
    "a1b = 0.0                    # Just to get this cell to run without errors, insert your answer here\n",
    "\n",
    "print(f\"a1b = ${a1b:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdb9d5e-a422-4295-94a6-ba9db542ecec",
   "metadata": {},
   "source": [
    "## **Problem Two: Backward Selection with the Ames Dataset**\n",
    "\n",
    "Now, repeat the same process as in Problem One, but using the `backward_feature_selection` algorithm from this week’s video notebook.\n",
    "\n",
    "**Steps to Follow:**\n",
    "1. **Observe** that we have provided the `backward_feature_selection` algorithm from this week's video notebook for you to use.\n",
    "2. **Run** the backward selection algorithm on the Ames dataset (`X_train` and `y_train`).\n",
    "3. **Plot** the results: Display the Root Mean Squared Error (RMSE) vs. the features removed by the algorithm.\n",
    "4. **Print** the Best Feature Set found by backward selection and the corresponding best CV RMSE Score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "413a71be-f510-43fa-8821-4715f3126e44",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Backward Feature Selection\n",
    "\n",
    "def backward_feature_selection(X, y, model, \n",
    "                               scoring='neg_mean_squared_error', \n",
    "                               cv=5, \n",
    "                               tol=None,               # None = no delta cutoff\n",
    "                                                       # use 0.0 for \"no further improvements\"\n",
    "                                                       # and 1e-4 for \"point of diminishing returns\"                                      \n",
    "                               max_features=None,      # If None, remove features until only 1 remains\n",
    "                                                       # Otherwise, stop when this many features remain\n",
    "                               n_jobs=-1,\n",
    "                               verbose=False\n",
    "                              ):\n",
    "    \n",
    "    # Helper function to compute CV score using LinearRegression\n",
    "    def cv_score(features):\n",
    "        return -cross_val_score(model, X[features], y, \n",
    "                                scoring=scoring, cv=cv, \n",
    "                                n_jobs=n_jobs          ).mean()\n",
    "    \n",
    "    # Start with all features (using a list for easier manipulation)\n",
    "    features_remaining = list(X.columns)\n",
    "    \n",
    "    # Compute initial CV score with the full feature set\n",
    "    initial_score = cv_score(features_remaining)\n",
    "    \n",
    "    # Initialize tracking variables\n",
    "    best_score        = initial_score                # Best (lowest) CV score observed so far\n",
    "    best_feature_set  = features_remaining.copy()    # Feature set corresponding to best_score\n",
    "    selected_features = ['NONE']                     # List to record the order in which features are removed\n",
    "    best_scores       = [initial_score]              # List to record the CV score after each removal (starting with full set)\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Start with full set of features:\")\n",
    "        print(f'{features_remaining}  CV score (MSE): {np.around(initial_score, 4)}\\n')\n",
    "    \n",
    "    # Determine the target number of features to keep:\n",
    "    # For backward elimination, if max_features is None, we remove until 1 feature remains.\n",
    "    target_feature_count = 1 if max_features is None else max_features\n",
    "    \n",
    "    prev_score = initial_score\n",
    "    round_num = 1\n",
    "    # Continue removing features until we reach the target count\n",
    "    while len(features_remaining) > target_feature_count:\n",
    "        if verbose:\n",
    "            print(f'Round {round_num}:')\n",
    "            \n",
    "        # Initialize variables to track the best removal in this round\n",
    "        lowest_score = float('inf')\n",
    "        feature_to_remove = None\n",
    "        best_new_features = None\n",
    "        \n",
    "        # Try removing each feature one at a time\n",
    "        for feature in features_remaining:\n",
    "            new_feature_set = features_remaining.copy()\n",
    "            new_feature_set.remove(feature)\n",
    "            new_score = cv_score(new_feature_set)\n",
    "            if verbose:\n",
    "                print('Trying removal of:',feature, np.around(new_score, 4))\n",
    "            if new_score < lowest_score:\n",
    "                lowest_score = new_score\n",
    "                feature_to_remove = feature\n",
    "                best_new_features = new_feature_set\n",
    "        \n",
    "        # Check if improvement is significant enough (if tol is set)\n",
    "        if tol is not None and (prev_score - lowest_score) < tol:\n",
    "            if verbose:\n",
    "                print(\"\\nStopping early due to minimal improvement.\")\n",
    "            break\n",
    "        \n",
    "        # Update the best score and feature set if current removal improves performance\n",
    "        if lowest_score < best_score:\n",
    "            best_score = lowest_score\n",
    "            best_feature_set = best_new_features.copy()\n",
    "        \n",
    "        # Update trackers for this round\n",
    "        prev_score = lowest_score\n",
    "        features_remaining = best_new_features\n",
    "        selected_features.append(feature_to_remove)\n",
    "        best_scores.append(lowest_score)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f'\\nRemoving {feature_to_remove}:  CV score (MSE) {np.around(lowest_score, 4)}\\n')\n",
    "        round_num += 1\n",
    "\n",
    "    return (\n",
    "        selected_features,      # Order in which features were removed\n",
    "        best_scores,            # CV scores after each removal step\n",
    "        best_feature_set,       # Feature set that achieved the best CV score\n",
    "        best_score              # Best (lowest) CV score\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6af2391-6f2a-4255-9eca-82e98fc3211e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:  Run Backward Feature Selection, plot the results, and print out the Best Feature Set and the Best CV RMSE Score found. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ec46ac-3d55-4107-bc8c-a3b53cf5984a",
   "metadata": {},
   "source": [
    "### Problem Two Graded Answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f1ea213-50a1-4b61-82b6-a5e66658032a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a2a = Ellipsis\n"
     ]
    }
   ],
   "source": [
    "# TODO:  Set the variable to the number of features in the best feature set found\n",
    "\n",
    "a2a = ...\n",
    "\n",
    "print(f'a2a = {a2a}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da9958c2-d0e1-4a3e-8297-f91c8adff8f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a2b = $0.00\n"
     ]
    }
   ],
   "source": [
    "# TODO:  Set the variable to the best CV RMSE score found\n",
    "\n",
    "a2b = 0.0                    # Just to get this cell to run without errors, insert your answer here\n",
    "\n",
    "print(f\"a2b = ${a2b:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75e62d6-b553-4dc8-bb7b-5439a260c5ce",
   "metadata": {},
   "source": [
    "## **Problem Three: Ridge Regression on the Ames Housing Dataset**\n",
    "\n",
    "In this problem, we will apply Ridge Regression to the Ames Housing dataset. Ridge Regression includes a hyperparameter $\\alpha$ that controls the strength of the regularization penalty, which helps prevent overfitting by constraining the growth of the model’s coefficients. A higher $\\alpha$ penalizes large coefficients more, while a lower $\\alpha$ allows them to grow larger.\n",
    "\n",
    "When creating the model, the parameter must be specified, for example:\n",
    "\n",
    "```python\n",
    "ridge_model = Ridge(alpha=100)\n",
    "```\n",
    "\n",
    "This introduces another instance of the model selection problem: we must determine the value of $\\alpha$ that yields the best CV RMSE score.\n",
    "\n",
    "**Steps to Follow:**\n",
    "\n",
    "1. **Standardize the Data:**  \n",
    "   Ridge regression is sensitive to the scale of the features, so we will use `StandardScaler` to standardize the feature set to have a mean of 0 and a standard deviation of 1 before training and testing. Note that the target variable does **not** need to be scaled.\n",
    "\n",
    "2. **Perform Cross-Validation Over a Range of Alpha Values:**  \n",
    "   For each $\\alpha \\in \\{100, 110, 120, \\dots, 500\\}$, calculate the cross-validation RMSE score for the model using 5-fold cross-validation.\n",
    "\n",
    "3. **Visualize the Results:**  \n",
    "   Plot the CV RMSE scores against the $\\alpha$ values.\n",
    "\n",
    "4. **Identify the Best Alpha:**  \n",
    "   Determine the $\\alpha$ that results in the minimum CV RMSE Score and print it out, along with the score.\n",
    "\n",
    "**Tip:** It would be an *excellent* idea to add the suffix `_scaled` to any set to which you apply scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4bdd7829-c8b5-4911-a739-e5e61b227b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb07668d-47c4-4928-bf7f-cf4ff0d6804f",
   "metadata": {},
   "source": [
    "### Problem Three Graded Answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a77a0908-06f0-414e-953f-19a541c1b8ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a3a = Ellipsis\n"
     ]
    }
   ],
   "source": [
    "# TODO:  Set the variable to the alpha determined to have the minimum CV RMSE score\n",
    "\n",
    "a3a = ...\n",
    "\n",
    "print(f'a3a = {a3a}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3a1af1c-3812-4bef-bb96-a2a258bc6999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a3b = $0.00\n"
     ]
    }
   ],
   "source": [
    "# TODO:  Set the variable to the minimum CV RMSE score found\n",
    "\n",
    "a3b = 0.0                    # Just to get this cell to run without errors, insert your answer here\n",
    "\n",
    "print(f\"a3b = ${a3b:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb57239-029f-4f53-8d8f-7ad5006a7b7e",
   "metadata": {},
   "source": [
    "## **Problem Four: Evaluate Your Best Model**\n",
    "\n",
    "In this final problem, you will identify the model with the best cross-validation RMSE score and evaluate its performance on the held-out test set.\n",
    "\n",
    "#### **Steps to Follow:**\n",
    "\n",
    "1. **Identify the Best Model:**\n",
    "   From your previous results, select the model that achieved the lowest CV RMSE score.\n",
    "\n",
    "3. **Train and Test the Selected Model:** \n",
    "   - For Forward or Backward Feature Selection:  Train a Linear Regression model using `X_train` **restricted to the selected best feature set**, and evaluate it on `X_test` restricted to the same feature set.\n",
    "   - For Ridge Regression:   Train a Ridge Regression model using the best alpha found from cross-validation, with `StandardScaler` applied to both `X_train` and `X_test` before training and testing.\n",
    "\n",
    "4. **Report Your Results:**\n",
    "   Print the name of the best model and the test RMSE in dollars.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bea61bba-4433-4928-9a5b-8dd281ca1ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebfb8c7-c0a8-4dc0-841e-2d6e36634dba",
   "metadata": {},
   "source": [
    "### Problem Four Graded Answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58bc980c-7057-4acf-90c5-6d531685a29d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a4a = Ellipsis\n"
     ]
    }
   ],
   "source": [
    "# TODO:  Set the variable to the best model, according to the CV RMSE score\n",
    "\n",
    "a4a = ...                    # should be one of:  1 = Forward selection, 2 = Backward selection, or 3 = Ridge\n",
    "\n",
    "print(f'a4a = {a4a}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4debeb28-a3e4-42b7-8ae3-a0ca96fec364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a4b = $0.00\n"
     ]
    }
   ],
   "source": [
    "# TODO:  Set the variable to the test RMSE for the best model\n",
    "\n",
    "a4b = 0.0                    # Just to get this cell to run without errors, insert your answer here\n",
    "\n",
    "print(f\"a4b = ${a4b:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e8a08b-fdaa-4aaf-9448-a2064374ee3e",
   "metadata": {},
   "source": [
    "### Final question...\n",
    "\n",
    "Why didn't we evaluate *all* the models on the test set and compare them?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205d669d-667d-4c35-9e8c-a065bc8082b7",
   "metadata": {},
   "source": [
    "### Optional\n",
    "\n",
    "A better way to evaluate models, as we saw in the last homework, is to use repeated CV scoring to select the best model. We didn't do it in this homework because it results in long run times unless you have good computing resources. It would be an *excellent exercise* to redo the code above and see how repeated CV scoring affects the outcomes. For purposes of grading, however, just do the homework as stated. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
